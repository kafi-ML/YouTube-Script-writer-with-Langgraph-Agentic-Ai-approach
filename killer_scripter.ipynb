{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9adf81bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import operator\n",
    "import os\n",
    "import re\n",
    "from datetime import date, datetime, timedelta\n",
    "from pathlib import Path\n",
    "from typing import TypedDict, List, Optional, Literal, Annotated\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.types import Send\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6756fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 1) Schemas\n",
    "# -----------------------------\n",
    "class Task(BaseModel):\n",
    "    id: int\n",
    "    title: str\n",
    "\n",
    "    goal: str = Field(\n",
    "        ...,\n",
    "        description=\"One sentence describing what the viewer should understand/feel after this segment.\",\n",
    "    )\n",
    "    # For scripts we use 'beats' (short spoken subpoints) instead of blog bullets\n",
    "    beats: List[str] = Field(\n",
    "        ...,\n",
    "        min_length=2,\n",
    "        max_length=8,\n",
    "        description=\"2–8 spoken beats or bullets to cover in this segment.\",\n",
    "    )\n",
    "    # target duration in seconds (preferred for scripts)\n",
    "    target_duration_sec: int = Field(..., description=\"Target duration for the segment in seconds.\")\n",
    "\n",
    "    tags: List[str] = Field(default_factory=list)\n",
    "    requires_research: bool = False\n",
    "    requires_citations: bool = False\n",
    "    requires_code: bool = False\n",
    "\n",
    "\n",
    "class Plan(BaseModel):\n",
    "    # script-centric fields\n",
    "    script_title: str\n",
    "    platform: str  # e.g. \"youtube\", \"podcast\", \"tiktok\"\n",
    "    tone: str\n",
    "\n",
    "    # tells workers what genre this is (prevents drift)\n",
    "    script_type: Literal[\"explainer\", \"story\", \"tutorial\", \"news_roundup\", \"comparison\", \"system_design\"] = \"explainer\"\n",
    "\n",
    "    constraints: List[str] = Field(default_factory=list)\n",
    "    tasks: List[Task]\n",
    "\n",
    "\n",
    "class EvidenceItem(BaseModel):\n",
    "    title: str\n",
    "    url: str\n",
    "    published_at: Optional[str] = None  # prefer ISO \"YYYY-MM-DD\"\n",
    "    snippet: Optional[str] = None\n",
    "    source: Optional[str] = None\n",
    "\n",
    "\n",
    "class RouterDecision(BaseModel):\n",
    "    needs_research: bool\n",
    "    mode: Literal[\"closed_book\", \"hybrid\", \"open_book\"]\n",
    "    reason: str\n",
    "    queries: List[str] = Field(default_factory=list)\n",
    "    max_results_per_query: int = Field(5, description=\"How many results to fetch per query (3–8).\")\n",
    "\n",
    "\n",
    "class EvidencePack(BaseModel):\n",
    "    evidence: List[EvidenceItem] = Field(default_factory=list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055c052b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    topic: str\n",
    "\n",
    "    # routing / research\n",
    "    mode: str\n",
    "    needs_research: bool\n",
    "    queries: List[str]\n",
    "    evidence: List[dict]            # store evidence as dicts, not Pydantic objects\n",
    "    plan: Optional[Plan]\n",
    "\n",
    "    # recency control\n",
    "    as_of: str\n",
    "    recency_days: int\n",
    "\n",
    "    # workers\n",
    "    sections: Annotated[List[tuple[int, str]], operator.add]\n",
    "    final: str\n",
    "\n",
    "    # new: audience and output descriptors for router rules\n",
    "    audience: Optional[dict]\n",
    "    output: Optional[dict]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1e1742",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b544de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 3) Router (decide upfront)\n",
    "# -----------------------------\n",
    "ROUTER_SYSTEM = \"\"\"\n",
    "You are a content-routing expert.\n",
    "\n",
    "Your job is to decide whether this topic requires web research\n",
    "based on volatility, recency sensitivity, and factual risk.\n",
    "\n",
    "Definitions:\n",
    "- closed_book: evergreen concepts, theory, fundamentals\n",
    "- hybrid: mostly evergreen, but examples/tools/models must be current\n",
    "- open_book: time-sensitive, news, rankings, weekly/monthly updates\n",
    "\n",
    "Rules:\n",
    "- If audience.level == beginner, lean toward closed_book unless clearly news.\n",
    "- If output.platform == youtube and topic implies \"latest\", prefer hybrid/open.\n",
    "- Generate 3–8 precise search queries if research is needed.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def router_node(state: State) -> dict:\n",
    "    topic = state[\"topic\"]\n",
    "    decider = llm.with_structured_output(RouterDecision)\n",
    "\n",
    "    # include the audience/output context so the router can use platform/audience rules\n",
    "    human = HumanMessage(content=(\n",
    "        f\"Topic: {topic}\\n\"\n",
    "        f\"As-of date: {state['as_of']}\\n\"\n",
    "        f\"Audience: {state.get('audience')}\\n\"\n",
    "        f\"Output: {state.get('output')}\\n\"\n",
    "    ))\n",
    "\n",
    "    decision = decider.invoke([SystemMessage(content=ROUTER_SYSTEM), human])\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def router_node(state: State) -> dict:\n",
    "    topic = state[\"topic\"]\n",
    "    decider = llm.with_structured_output(RouterDecision)\n",
    "\n",
    "    human = HumanMessage(content=(\n",
    "        f\"Topic: {topic}\\n\"\n",
    "        f\"As-of date: {state['as_of']}\\n\"\n",
    "        f\"Audience: {state.get('audience')}\\n\"\n",
    "        f\"Output: {state.get('output')}\\n\"\n",
    "    ))\n",
    "\n",
    "    decision = decider.invoke(\n",
    "        [\n",
    "            SystemMessage(content=ROUTER_SYSTEM),\n",
    "            human\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Set default recency window based on mode\n",
    "    if decision.mode == \"open_book\":\n",
    "        recency_days = 7\n",
    "    elif decision.mode == \"hybrid\":\n",
    "        recency_days = 45\n",
    "    else:\n",
    "        recency_days = 3650\n",
    "\n",
    "    return {\n",
    "        \"needs_research\": decision.needs_research,\n",
    "        \"mode\": decision.mode,\n",
    "        \"queries\": decision.queries,\n",
    "        \"recency_days\": recency_days,\n",
    "    }\n",
    "\n",
    "def route_next(state: State) -> str:\n",
    "    return \"research\" if state[\"needs_research\"] else \"orchestrator\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87e6015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 4) Research (Tavily)\n",
    "# -----------------------------\n",
    "def _tavily_search(query: str, max_results: int = 5) -> List[dict]:\n",
    "    \"\"\"\n",
    "    Uses TavilySearchResults if installed and TAVILY_API_KEY is set.\n",
    "    Returns list of dict with common fields. Note: published date is often missing.\n",
    "    \"\"\"\n",
    "    tool = TavilySearchResults(max_results=max_results)\n",
    "    results = tool.invoke({\"query\": query})\n",
    "\n",
    "    normalized: List[dict] = []\n",
    "    for r in results or []:\n",
    "        normalized.append(\n",
    "            {\n",
    "                \"title\": r.get(\"title\") or \"\",\n",
    "                \"url\": r.get(\"url\") or \"\",\n",
    "                \"snippet\": r.get(\"content\") or r.get(\"snippet\") or \"\",\n",
    "                \"published_at\": r.get(\"published_date\") or r.get(\"published_at\"),\n",
    "                \"source\": r.get(\"source\"),\n",
    "            }\n",
    "        )\n",
    "    return normalized\n",
    "\n",
    "\n",
    "def _iso_to_date(s: Optional[str]) -> Optional[date]:\n",
    "    if not s:\n",
    "        return None\n",
    "    try:\n",
    "        return date.fromisoformat(s[:10])\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "RESEARCH_SYSTEM = \"\"\"You are a research synthesizer for technical writing.\n",
    "\n",
    "Given raw web search results, produce a deduplicated list of EvidenceItem objects.\n",
    "\n",
    "Rules:\n",
    "- Only include items with a non-empty url.\n",
    "- Prefer relevant + authoritative sources (company blogs, docs, reputable outlets).\n",
    "- Extract/normalize published_at as ISO (YYYY-MM-DD) if you can infer it from title/snippet.\n",
    "  If you can't infer a date reliably, set published_at=null (do NOT guess).\n",
    "- Keep snippets short.\n",
    "- Deduplicate by URL.\n",
    "\"\"\"\n",
    "\n",
    "def research_node(state: State) -> dict:\n",
    "    queries = (state.get(\"queries\", []) or [])[:10]\n",
    "    max_results = 6\n",
    "\n",
    "    raw_results: List[dict] = []\n",
    "    for q in queries:\n",
    "        raw_results.extend(_tavily_search(q, max_results=max_results))\n",
    "\n",
    "    if not raw_results:\n",
    "        return {\"evidence\": []}\n",
    "\n",
    "    extractor = llm.with_structured_output(EvidencePack)\n",
    "    pack = extractor.invoke(\n",
    "        [\n",
    "            SystemMessage(content=RESEARCH_SYSTEM),\n",
    "            HumanMessage(\n",
    "                content=(\n",
    "                    f\"As-of date: {state['as_of']}\\n\"\n",
    "                    f\"Recency days: {state['recency_days']}\\n\\n\"\n",
    "                    f\"Raw results:\\n{raw_results}\"\n",
    "                )\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Deduplicate by URL\n",
    "    dedup = {}\n",
    "    for e in pack.evidence:\n",
    "        if e.url:\n",
    "            dedup[e.url] = e\n",
    "    evidence = list(dedup.values())\n",
    "\n",
    "    # HARD RECENCY FILTER for open_book weekly roundup:\n",
    "    # keep only items with a parseable ISO date and within the window.\n",
    "    mode = state.get(\"mode\", \"closed_book\")\n",
    "    if mode == \"open_book\":\n",
    "        as_of = date.fromisoformat(state[\"as_of\"])\n",
    "        cutoff = as_of - timedelta(days=int(state[\"recency_days\"]))\n",
    "        fresh: List[EvidenceItem] = []\n",
    "        for e in evidence:\n",
    "            d = _iso_to_date(e.published_at)\n",
    "            if d and d >= cutoff:\n",
    "                fresh.append(e)\n",
    "        evidence = fresh\n",
    "\n",
    "    return {\"evidence\": evidence}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61b15d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 5) Orchestrator (Plan)\n",
    "# -----------------------------\n",
    "ORCH_SYSTEM = \"\"\"\n",
    "\n",
    "\n",
    "- youtube:\n",
    "  - first task MUST be a hook (0–15s)\n",
    "  - include pattern interrupts\n",
    "  - specify target_duration_sec for each tas\n",
    "\n",
    "\n",
    "\n",
    "You are a senior content architect.\n",
    "\n",
    "You design a high-retention content plan tailored to:\n",
    "- audience profile\n",
    "- platform\n",
    "- attention span\n",
    "- depth preference\n",
    "\n",
    "HARD RULES:\n",
    "- Create 5–9 tasks.\n",
    "- Each task must have:\n",
    "  - clear goal\n",
    "  - concrete bullets\n",
    "  - target_size (words or seconds)\n",
    "\n",
    "PLATFORM RULES:\n",
    "- blog:\n",
    "  - logical flow\n",
    "  - depth scales with audience.level\n",
    "- youtube:\n",
    "  - first task MUST be a hook (0–15s)\n",
    "  - include pattern interrupts\n",
    "  - shorter segments for short attention_span\n",
    "- linkedin/twitter:\n",
    "  - compress ideas\n",
    "  - focus on insight, not completeness\n",
    "\n",
    "AUDIENCE RULES:\n",
    "- beginner:\n",
    "  - avoid jargon unless explained\n",
    "  - include intuition\n",
    "- expert:\n",
    "  - assume prior knowledge\n",
    "  - include edge cases, tradeoffs\n",
    "- founder/general:\n",
    "  - focus on impact, cost, decisions\n",
    "\n",
    "DEPTH RULES:\n",
    "- surface → conceptual overview\n",
    "- deep → implementation reasoning\n",
    "- hardcore → internals, failure modes, tradeoffs\n",
    "\n",
    "QUALITY BAR:\n",
    "- Tasks must NOT overlap.\n",
    "- At least one task should include:\n",
    "  - failure modes OR\n",
    "  - performance/cost OR\n",
    "  - security implications\n",
    "\n",
    "OUTPUT MUST MATCH ContentPlan SCHEMA EXACTLY.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def orchestrator_node(state: State) -> dict:\n",
    "    planner = llm.with_structured_output(Plan)\n",
    "    evidence = state.get(\"evidence\", [])\n",
    "    mode = state.get(\"mode\", \"closed_book\")\n",
    "\n",
    "    # Force blog_kind for open_book\n",
    "    forced_kind = \"news_roundup\" if mode == \"open_book\" else None\n",
    "\n",
    "    plan = planner.invoke(\n",
    "        [\n",
    "            SystemMessage(content=ORCH_SYSTEM),\n",
    "            HumanMessage(\n",
    "                content=(\n",
    "                    f\"Topic: {state['topic']}\\n\"\n",
    "                    f\"Mode: {mode}\\n\"\n",
    "                    f\"As-of: {state['as_of']} (recency_days={state['recency_days']})\\n\"\n",
    "                    f\"{'Force blog_kind=news_roundup' if forced_kind else ''}\\n\\n\"\n",
    "                    f\"Evidence (ONLY use for fresh claims; may be empty):\\n\"\n",
    "                    f\"{[e.model_dump() for e in evidence][:16]}\\n\\n\"\n",
    "                    f\"Instruction: If mode=open_book, your plan must NOT drift into a tutorial.\"\n",
    "                )\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Ensure open_book forces the kind even if model forgets\n",
    "    if forced_kind:\n",
    "        plan.blog_kind = \"news_roundup\"\n",
    "\n",
    "    return {\"plan\": plan}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a04da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 6) Fanout\n",
    "# -----------------------------\n",
    "def fanout(state: State):\n",
    "    assert state[\"plan\"] is not None\n",
    "    return [\n",
    "        Send(\n",
    "            \"worker\",\n",
    "            {\n",
    "                \"task\": task.model_dump(),\n",
    "                \"topic\": state[\"topic\"],\n",
    "                \"mode\": state[\"mode\"],\n",
    "                \"as_of\": state[\"as_of\"],\n",
    "                \"recency_days\": state[\"recency_days\"],\n",
    "                \"plan\": state[\"plan\"].model_dump(),\n",
    "                \"evidence\": [e.model_dump() for e in state.get(\"evidence\", [])],\n",
    "            },\n",
    "        )\n",
    "        for task in state[\"plan\"].tasks\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d06b481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 7) Worker (write one section)\n",
    "# -----------------------------\n",
    "WORKER_SYSTEM =  \"\"\"\n",
    "You are a professional scriptwriter for spoken-word content.\n",
    "\n",
    "Write EXACTLY ONE spoken content segment.\n",
    "\n",
    "STRICT RULES:\n",
    "- Follow the Task goal and beats exactly and in order.\n",
    "- Respect target_duration_sec (±15%).\n",
    "  - Use ~130 words/min as default pacing (approx 2.17 words/sec) when asked to estimate words.\n",
    "- Output ONLY the spoken segment, no H1/H2 headings, no article-style metadata.\n",
    "\n",
    "STYLE:\n",
    "- Spoken language, short sentences, natural rhythm.\n",
    "- Use stage directions in brackets when needed: [PAUSE], [ON SCREEN], [B-ROLL], [SFX].\n",
    "- Include an optional short \"read time\" or estimated seconds in a single-line comment at the top like: <!-- ~45s --> (only if requested).\n",
    "\n",
    "GROUNDING:\n",
    "- If requires_citations==True or mode==open_book, cite ONLY the provided Evidence URLs in-line as: [Source](URL).\n",
    "- If not supported by evidence, write: \"Not found in provided sources.\"\n",
    "\n",
    "CODE:\n",
    "- If requires_code==True, include a short code block and a one-sentence explainer.\n",
    "\n",
    "TONE CONTROL:\n",
    "- calm, analytical, authoritative, hype — follow the plan.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def worker_node(payload: dict) -> dict:\n",
    "    task = Task(**payload[\"task\"])\n",
    "    plan = Plan(**payload[\"plan\"])\n",
    "    evidence = [EvidenceItem(**e) for e in payload.get(\"evidence\", [])]  # ok to parse\n",
    "    topic = payload[\"topic\"]\n",
    "    mode = payload.get(\"mode\", \"closed_book\")\n",
    "    as_of = payload.get(\"as_of\")\n",
    "    recency_days = payload.get(\"recency_days\")\n",
    "\n",
    "    # convert beats\n",
    "    beats_text = \"\\n- \" + \"\\n- \".join(task.beats)\n",
    "\n",
    "    # estimate words from seconds for prompt help (130 wpm => ~2.17 words/sec)\n",
    "    est_words = int(task.target_duration_sec * 2.17)\n",
    "\n",
    "    evidence_text = \"\"\n",
    "    if evidence:\n",
    "        evidence_text = \"\\n\".join(\n",
    "            f\"- {e.title} | {e.url} | {e.published_at or 'date:unknown'}\".strip()\n",
    "            for e in evidence[:20]\n",
    "        )\n",
    "\n",
    "    # Compose prompt with script-focused fields\n",
    "    msg = (\n",
    "        f\"Script title: {plan.script_title}\\n\"\n",
    "        f\"Platform: {plan.platform}\\n\"\n",
    "        f\"Tone: {plan.tone}\\n\"\n",
    "        f\"Script type: {plan.script_type}\\n\"\n",
    "        f\"Constraints: {plan.constraints}\\n\"\n",
    "        f\"Topic: {topic}\\n\"\n",
    "        f\"Mode: {mode}\\n\"\n",
    "        f\"As-of: {as_of} (recency_days={recency_days})\\n\\n\"\n",
    "        f\"Segment title: {task.title}\\n\"\n",
    "        f\"Goal: {task.goal}\\n\"\n",
    "        f\"Target duration (sec): {task.target_duration_sec} (~{est_words} words)\\n\"\n",
    "        f\"Tags: {task.tags}\\n\"\n",
    "        f\"requires_research: {task.requires_research}\\n\"\n",
    "        f\"requires_citations: {task.requires_citations}\\n\"\n",
    "        f\"requires_code: {task.requires_code}\\n\"\n",
    "        f\"Beats:{beats_text}\\n\\n\"\n",
    "        f\"Evidence (ONLY use these URLs when citing):\\n{evidence_text}\\n\"\n",
    "    )\n",
    "\n",
    "    section_text = llm.invoke([SystemMessage(content=WORKER_SYSTEM), HumanMessage(content=msg)]).content.strip()\n",
    "    return {\"sections\": [(task.id, section_text)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44285e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 8) Reducer (merge + save)\n",
    "# -----------------------------\n",
    "def reducer_node(state: State) -> dict:\n",
    "    plan = state[\"plan\"]\n",
    "    if plan is None:\n",
    "        raise ValueError(\"Reducer called without a plan.\")\n",
    "\n",
    "    ordered_sections = [md for _, md in sorted(state[\"sections\"], key=lambda x: x[0])]\n",
    "    body = \"\\n\\n\".join(ordered_sections).strip()\n",
    "\n",
    "    # For scripts use a header line and plain text\n",
    "    final_script = f\"{plan.script_title}\\n\\n{body}\\n\"\n",
    "    filename = f\"{plan.script_title}.txt\"\n",
    "    Path(filename).write_text(final_script, encoding=\"utf-8\")\n",
    "\n",
    "    return {\"final\": final_script}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46808c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 9) Build graph\n",
    "# -----------------------------\n",
    "g = StateGraph(State)\n",
    "g.add_node(\"router\", router_node)\n",
    "g.add_node(\"research\", research_node)\n",
    "g.add_node(\"orchestrator\", orchestrator_node)\n",
    "g.add_node(\"worker\", worker_node)\n",
    "g.add_node(\"reducer\", reducer_node)\n",
    "\n",
    "g.add_edge(START, \"router\")\n",
    "g.add_conditional_edges(\"router\", route_next, {\"research\": \"research\", \"orchestrator\": \"orchestrator\"})\n",
    "g.add_edge(\"research\", \"orchestrator\")\n",
    "\n",
    "g.add_conditional_edges(\"orchestrator\", fanout, [\"worker\"])\n",
    "g.add_edge(\"worker\", \"reducer\")\n",
    "g.add_edge(\"reducer\", END)\n",
    "\n",
    "app = g.compile()\n",
    "\n",
    "app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d324cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(topic: str, as_of: Optional[str] = None, audience: Optional[dict] = None, output: Optional[dict] = None):\n",
    "    if as_of is None:\n",
    "        as_of = date.today().isoformat()\n",
    "    if audience is None:\n",
    "        audience = {\"level\": \"beginner\"}\n",
    "    if output is None:\n",
    "        output = {\"platform\": \"youtube\", \"delivery_style\": \"calm\"}\n",
    "\n",
    "    out = app.invoke(\n",
    "        {\n",
    "            \"topic\": topic,\n",
    "            \"mode\": \"\",\n",
    "            \"audience\": audience,\n",
    "            \"output\": output,\n",
    "            \"needs_research\": False,\n",
    "            \"queries\": [],\n",
    "            \"evidence\": [],\n",
    "            \"plan\": None,\n",
    "            \"as_of\": as_of,\n",
    "            \"recency_days\": 7,   # router may overwrite\n",
    "            \"sections\": [],\n",
    "            \"final\": \"\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    plan: Plan = out[\"plan\"]\n",
    "    print(\"\\n\" + \"=\" * 100)\n",
    "    print(\"TOPIC:\", topic)\n",
    "    print(\"AS_OF:\", out.get(\"as_of\"), \"RECENCY_DAYS:\", out.get(\"recency_days\"))\n",
    "    print(\"MODE:\", out.get(\"mode\"))\n",
    "    print(\"BLOG_KIND:\", plan.blog_kind)\n",
    "    print(\"NEEDS_RESEARCH:\", out.get(\"needs_research\"))\n",
    "    print(\"QUERIES:\", (out.get(\"queries\") or [])[:6])\n",
    "    print(\"EVIDENCE_COUNT:\", len(out.get(\"evidence\", [])))\n",
    "    if out.get(\"evidence\"):\n",
    "        print(\"EVIDENCE_SAMPLE:\", [e.model_dump() for e in out[\"evidence\"][:2]])\n",
    "    print(\"TASKS:\", len(plan.tasks))\n",
    "    print(\"SAVED_MD_CHARS:\", len(out.get(\"final\", \"\")))\n",
    "    print(\"=\" * 100 + \"\\n\")\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19278e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    run(\n",
    "        topic=\"Self Attention explained intuitively\",\n",
    "        audience={\n",
    "            \"level\": \"beginner\",\n",
    "            \"persona\": \"student\",\n",
    "            \"attention_span\": \"medium\",\n",
    "            \"prefers_examples\": True,\n",
    "            \"prefers_code\": False\n",
    "        },\n",
    "        output={\n",
    "            \"platform\": \"youtube\",\n",
    "            \"delivery_style\": \"calm\",\n",
    "            \"depth\": \"surface\",\n",
    "            \"include_cta\": True\n",
    "        }\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fd2eb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
